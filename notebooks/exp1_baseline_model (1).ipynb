{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu6Q9XBcJUYc"
      },
      "source": [
        "# project path\n",
        "\n",
        " - E:\\Campus-X\\campusx_mlops\\campusx_project\\mlops-mini-project\\notebooks\n",
        "\n",
        " - https://github.com/campusx-official/mlops-mini-project/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "688daeb9",
        "outputId": "3c3f28de-25da-4573-a84a-a98557fd6082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q mlflow pandas scikit-learn nltk numpy dagshub dvc jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jupyter\n",
            "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting notebook (from jupyter)\n",
            "  Using cached notebook-7.4.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jupyter-console (from jupyter)\n",
            "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nbconvert (from jupyter)\n",
            "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: ipykernel in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyter) (6.30.1)\n",
            "Collecting ipywidgets (from jupyter)\n",
            "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting jupyterlab (from jupyter)\n",
            "  Using cached jupyterlab-4.4.7-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: comm>=0.1.1 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (0.2.3)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (1.8.16)\n",
            "Requirement already satisfied: ipython>=7.23.1 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (9.5.0)\n",
            "Requirement already satisfied: jupyter-client>=8.0.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio>=1.4 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
            "Requirement already satisfied: packaging>=22 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (25.0)\n",
            "Requirement already satisfied: psutil>=5.7 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
            "Requirement already satisfied: pyzmq>=25 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (27.1.0)\n",
            "Requirement already satisfied: tornado>=6.2 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (6.5.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
            "Requirement already satisfied: colorama in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
            "Requirement already satisfied: decorator in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (2.19.2)\n",
            "Requirement already satisfied: stack_data in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel->jupyter) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.4.0)\n",
            "Requirement already satisfied: pywin32>=300 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (311)\n",
            "Requirement already satisfied: six>=1.5 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->jupyter) (1.17.0)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter)\n",
            "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter)\n",
            "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
            "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
            "  Using cached jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
            "  Using cached jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
            "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
            "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyterlab->jupyter) (80.9.0)\n",
            "Requirement already satisfied: anyio in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.10.0)\n",
            "Requirement already satisfied: certifi in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
            "Requirement already satisfied: idna in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
            "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pywinpty>=2.0.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached pywinpty-3.0.0-cp312-cp312-win_amd64.whl.metadata (101 bytes)\n",
            "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Using cached json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: requests>=2.31 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.5)\n",
            "Requirement already satisfied: sniffio>=1.1 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (4.15.0)\n",
            "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-win_amd64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab->jupyter) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Using cached rpds_py-0.27.1-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting beautifulsoup4 (from nbconvert->jupyter)\n",
            "  Using cached beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
            "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting defusedxml (from nbconvert->jupyter)\n",
            "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
            "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
            "  Using cached mistune-3.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
            "  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
            "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter)\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
            "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
            "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
            "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.0)\n",
            "Requirement already satisfied: pycparser in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.23)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter)\n",
            "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: arrow>=0.15.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20250822)\n",
            "Requirement already satisfied: executing>=1.2.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in e:\\campus-x\\campusx_mlops\\campusx_projectt\\.myvenv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
            "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
            "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Using cached jupyterlab-4.4.7-py3-none-any.whl (12.3 MB)\n",
            "Using cached jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
            "Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
            "Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
            "Using cached json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
            "Using cached mistune-3.1.4-py3-none-any.whl (53 kB)\n",
            "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
            "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
            "Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
            "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
            "Using cached fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
            "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
            "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Using cached prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
            "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Using cached pywinpty-3.0.0-cp312-cp312-win_amd64.whl (2.1 MB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Using cached rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
            "Using cached lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "Using cached rpds_py-0.27.1-cp312-cp312-win_amd64.whl (232 kB)\n",
            "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
            "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
            "Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
            "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-win_amd64.whl (31 kB)\n",
            "Using cached beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
            "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
            "Using cached notebook-7.4.5-py3-none-any.whl (14.3 MB)\n",
            "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: webencodings, fastjsonschema, widgetsnbextension, websocket-client, webcolors, uri-template, tinycss2, soupsieve, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pywinpty, python-json-logger, prometheus-client, pandocfilters, mistune, lark, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, fqdn, defusedxml, bleach, babel, async-lru, terminado, rfc3987-syntax, referencing, beautifulsoup4, argon2-cffi-bindings, jupyter-server-terminals, jsonschema-specifications, isoduration, ipywidgets, argon2-cffi, jupyter-console, jsonschema, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
            "\n",
            "    ---------------------------------------  1/50 [fastjsonschema]\n",
            "    ---------------------------------------  1/50 [fastjsonschema]\n",
            "   -- -------------------------------------  3/50 [websocket-client]\n",
            "   -- -------------------------------------  3/50 [websocket-client]\n",
            "   -- -------------------------------------  3/50 [websocket-client]\n",
            "   -- -------------------------------------  3/50 [websocket-client]\n",
            "   --- ------------------------------------  4/50 [webcolors]\n",
            "   ---- -----------------------------------  5/50 [uri-template]\n",
            "   ---- -----------------------------------  6/50 [tinycss2]\n",
            "   ----- ----------------------------------  7/50 [soupsieve]\n",
            "   ----- ----------------------------------  7/50 [soupsieve]\n",
            "   ------ ---------------------------------  8/50 [send2trash]\n",
            "   ------ ---------------------------------  8/50 [send2trash]\n",
            "   -------- ------------------------------- 10/50 [rfc3986-validator]\n",
            "   -------- ------------------------------- 11/50 [rfc3339-validator]\n",
            "   --------- ------------------------------ 12/50 [pywinpty]\n",
            "   ---------- ----------------------------- 13/50 [python-json-logger]\n",
            "   ----------- ---------------------------- 14/50 [prometheus-client]\n",
            "   ----------- ---------------------------- 14/50 [prometheus-client]\n",
            "   ----------- ---------------------------- 14/50 [prometheus-client]\n",
            "   ----------- ---------------------------- 14/50 [prometheus-client]\n",
            "   ------------ --------------------------- 16/50 [mistune]\n",
            "   ------------ --------------------------- 16/50 [mistune]\n",
            "   ------------ --------------------------- 16/50 [mistune]\n",
            "   ------------ --------------------------- 16/50 [mistune]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   ------------- -------------------------- 17/50 [lark]\n",
            "   -------------- ------------------------- 18/50 [jupyterlab_widgets]\n",
            "   --------------- ------------------------ 19/50 [jupyterlab-pygments]\n",
            "   ---------------- ----------------------- 20/50 [jsonpointer]\n",
            "   ---------------- ----------------------- 21/50 [json5]\n",
            "   ---------------- ----------------------- 21/50 [json5]\n",
            "   ------------------ --------------------- 23/50 [defusedxml]\n",
            "   ------------------ --------------------- 23/50 [defusedxml]\n",
            "   ------------------ --------------------- 23/50 [defusedxml]\n",
            "   ------------------ --------------------- 23/50 [defusedxml]\n",
            "   ------------------- -------------------- 24/50 [bleach]\n",
            "   ------------------- -------------------- 24/50 [bleach]\n",
            "   ------------------- -------------------- 24/50 [bleach]\n",
            "   ------------------- -------------------- 24/50 [bleach]\n",
            "   ------------------- -------------------- 24/50 [bleach]\n",
            "   ------------------- -------------------- 24/50 [bleach]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 25/50 [babel]\n",
            "   -------------------- ------------------- 26/50 [async-lru]\n",
            "   --------------------- ------------------ 27/50 [terminado]\n",
            "   ---------------------- ----------------- 28/50 [rfc3987-syntax]\n",
            "   ----------------------- ---------------- 29/50 [referencing]\n",
            "   ------------------------ --------------- 30/50 [beautifulsoup4]\n",
            "   ------------------------ --------------- 30/50 [beautifulsoup4]\n",
            "   ------------------------ --------------- 30/50 [beautifulsoup4]\n",
            "   ------------------------ --------------- 30/50 [beautifulsoup4]\n",
            "   ------------------------ --------------- 30/50 [beautifulsoup4]\n",
            "   ------------------------- -------------- 32/50 [jupyter-server-terminals]\n",
            "   -------------------------- ------------- 33/50 [jsonschema-specifications]\n",
            "   --------------------------- ------------ 34/50 [isoduration]\n",
            "   ---------------------------- ----------- 35/50 [ipywidgets]\n",
            "   ---------------------------- ----------- 35/50 [ipywidgets]\n",
            "   ---------------------------- ----------- 35/50 [ipywidgets]\n",
            "   ---------------------------- ----------- 35/50 [ipywidgets]\n",
            "   ---------------------------- ----------- 35/50 [ipywidgets]\n",
            "   ---------------------------- ----------- 35/50 [ipywidgets]\n",
            "   ---------------------------- ----------- 35/50 [ipywidgets]\n",
            "   ---------------------------- ----------- 36/50 [argon2-cffi]\n",
            "   ----------------------------- ---------- 37/50 [jupyter-console]\n",
            "   ------------------------------ --------- 38/50 [jsonschema]\n",
            "   ------------------------------ --------- 38/50 [jsonschema]\n",
            "   ------------------------------ --------- 38/50 [jsonschema]\n",
            "   ------------------------------ --------- 38/50 [jsonschema]\n",
            "   ------------------------------ --------- 38/50 [jsonschema]\n",
            "   ------------------------------- -------- 39/50 [nbformat]\n",
            "   ------------------------------- -------- 39/50 [nbformat]\n",
            "   ------------------------------- -------- 39/50 [nbformat]\n",
            "   ------------------------------- -------- 39/50 [nbformat]\n",
            "   -------------------------------- ------- 40/50 [nbclient]\n",
            "   -------------------------------- ------- 40/50 [nbclient]\n",
            "   -------------------------------- ------- 41/50 [jupyter-events]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   --------------------------------- ------ 42/50 [nbconvert]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ---------------------------------- ----- 43/50 [jupyter-server]\n",
            "   ----------------------------------- ---- 44/50 [notebook-shim]\n",
            "   ----------------------------------- ---- 44/50 [notebook-shim]\n",
            "   ----------------------------------- ---- 44/50 [notebook-shim]\n",
            "   ----------------------------------- ---- 44/50 [notebook-shim]\n",
            "   ------------------------------------ --- 45/50 [jupyterlab-server]\n",
            "   ------------------------------------ --- 45/50 [jupyterlab-server]\n",
            "   ------------------------------------ --- 45/50 [jupyterlab-server]\n",
            "   ------------------------------------ --- 46/50 [jupyter-lsp]\n",
            "   ------------------------------------ --- 46/50 [jupyter-lsp]\n",
            "   ------------------------------------ --- 46/50 [jupyter-lsp]\n",
            "   ------------------------------------ --- 46/50 [jupyter-lsp]\n",
            "   ------------------------------------ --- 46/50 [jupyter-lsp]\n",
            "   ------------------------------------ --- 46/50 [jupyter-lsp]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   ------------------------------------- -- 47/50 [jupyterlab]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   -------------------------------------- - 48/50 [notebook]\n",
            "   ---------------------------------------- 50/50 [jupyter]\n",
            "\n",
            "Successfully installed argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 async-lru-2.0.5 babel-2.17.0 beautifulsoup4-4.13.5 bleach-6.2.0 defusedxml-0.7.1 fastjsonschema-2.21.2 fqdn-1.5.1 ipywidgets-8.1.7 isoduration-20.11.0 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.7 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 lark-1.2.2 mistune-3.1.4 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.4.5 notebook-shim-0.2.4 pandocfilters-1.5.1 prometheus-client-0.22.1 python-json-logger-3.3.0 pywinpty-3.0.0 referencing-0.36.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.27.1 send2trash-1.8.3 soupsieve-2.8 terminado-0.18.1 tinycss2-1.4.0 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iIUEfagvKgE",
        "outputId": "0fb1cd87-2e8d-4917-d292-9a644e488151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# check the all installed installed version\n",
        "import dvc, mlflow, pandas, numpy, dagshub, sklearn, jupyter\n",
        "print(\"✅ All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X8MmGgr53iTQ"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "import mlflow.sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "L28lJddE4TOM",
        "outputId": "c790bf2e-9d06-4aa3-81d5-4b423034f849"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8475</th>\n",
              "      <td>1962195602</td>\n",
              "      <td>relief</td>\n",
              "      <td>@_HarryKim OOC:  It's okay.  Maybe our schedul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23813</th>\n",
              "      <td>1694705060</td>\n",
              "      <td>happiness</td>\n",
              "      <td>woo just made this, follow me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11258</th>\n",
              "      <td>1963157199</td>\n",
              "      <td>sadness</td>\n",
              "      <td>@arizonaobvious  that sucks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10017</th>\n",
              "      <td>1962803421</td>\n",
              "      <td>hate</td>\n",
              "      <td>damn fight night 4 demo won't load, keeps cras...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2729</th>\n",
              "      <td>1957614712</td>\n",
              "      <td>love</td>\n",
              "      <td>@BrianLimond but lorraine kelly is a sexy mama!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29145</th>\n",
              "      <td>1751106427</td>\n",
              "      <td>surprise</td>\n",
              "      <td>Off to prom. Say hi to me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35992</th>\n",
              "      <td>1753218064</td>\n",
              "      <td>worry</td>\n",
              "      <td>i had a vivid dream last night! i was crooning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8209</th>\n",
              "      <td>1962067688</td>\n",
              "      <td>relief</td>\n",
              "      <td>@bethanyshondark Ouch. Better get used to it. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6738</th>\n",
              "      <td>1961427598</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@moriagerard I haven't had one for a long time...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21756</th>\n",
              "      <td>1694293402</td>\n",
              "      <td>happiness</td>\n",
              "      <td>@cheergod2002 yeah I can tell ha ha.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         tweet_id  sentiment  \\\n",
              "8475   1962195602     relief   \n",
              "23813  1694705060  happiness   \n",
              "11258  1963157199    sadness   \n",
              "10017  1962803421       hate   \n",
              "2729   1957614712       love   \n",
              "29145  1751106427   surprise   \n",
              "35992  1753218064      worry   \n",
              "8209   1962067688     relief   \n",
              "6738   1961427598    neutral   \n",
              "21756  1694293402  happiness   \n",
              "\n",
              "                                                 content  \n",
              "8475   @_HarryKim OOC:  It's okay.  Maybe our schedul...  \n",
              "23813                      woo just made this, follow me  \n",
              "11258                        @arizonaobvious  that sucks  \n",
              "10017  damn fight night 4 demo won't load, keeps cras...  \n",
              "2729     @BrianLimond but lorraine kelly is a sexy mama!  \n",
              "29145                          Off to prom. Say hi to me  \n",
              "35992  i had a vivid dream last night! i was crooning...  \n",
              "8209   @bethanyshondark Ouch. Better get used to it. ...  \n",
              "6738   @moriagerard I haven't had one for a long time...  \n",
              "21756               @cheergod2002 yeah I can tell ha ha.  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv')\n",
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TPvUcNcS3iTT",
        "outputId": "dd5a770d-1a85-4bcd-f3fb-651b7d10a208"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                            content\n",
              "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                Funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends SOON!\n",
              "4     neutral  @dannycastillo We want to trade with someone w..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv').drop(columns=['tweet_id'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spQlxnV03iTU",
        "outputId": "55ec0954-65af-4e9d-86f7-cf420a00c068"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:33: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:33: SyntaxWarning: invalid escape sequence '\\s'\n",
            "C:\\Users\\aamir\\AppData\\Local\\Temp\\ipykernel_2956\\2725294146.py:33: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  text = re.sub('\\s+', ' ', text).strip()  # remove extra spaces\n"
          ]
        }
      ],
      "source": [
        "# data preprocessing\n",
        "\n",
        "# Define text preprocessing functions\n",
        "def lemmatization(text):\n",
        "    \"\"\"Lemmatize the text.\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()          # initialize lemmatizer\n",
        "    text = text.split()                       # split into words\n",
        "    text = [lemmatizer.lemmatize(word) for word in text]  # lemmatize each word\n",
        "    return \" \".join(text)                     # join back into string\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    \"\"\"Remove stop words from the text.\"\"\"\n",
        "    stop_words = set(stopwords.words(\"english\"))  # load stopwords\n",
        "    text = [word for word in str(text).split() if word not in stop_words]  # remove stopwords\n",
        "    return \" \".join(text)\n",
        "\n",
        "def removing_numbers(text):\n",
        "    \"\"\"Remove numbers from the text.\"\"\"\n",
        "    text = ''.join([char for char in text if not char.isdigit()])  # keep only non-digits\n",
        "    return text\n",
        "\n",
        "def lower_case(text):\n",
        "    \"\"\"Convert text to lower case.\"\"\"\n",
        "    text = text.split()                       # split into words\n",
        "    text = [word.lower() for word in text]    # convert to lowercase\n",
        "    return \" \".join(text)\n",
        "\n",
        "def removing_punctuations(text):\n",
        "    \"\"\"Remove punctuations from the text.\"\"\"\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)  # remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n",
        "    text = text.replace('؛', \"\")             # remove special char\n",
        "    text = re.sub('\\s+', ' ', text).strip()  # remove extra spaces\n",
        "    return text\n",
        "\n",
        "def removing_urls(text):\n",
        "    \"\"\"Remove URLs from the text.\"\"\"\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')  # regex for URLs\n",
        "    return url_pattern.sub(r'', text)                   # replace URLs with empty string\n",
        "\n",
        "def normalize_text(df):\n",
        "    \"\"\"Normalize the text data.\"\"\"\n",
        "    try:\n",
        "        df['content'] = df['content'].apply(lower_case)           # step 1: lowercase\n",
        "        df['content'] = df['content'].apply(remove_stop_words)    # step 2: remove stopwords\n",
        "        df['content'] = df['content'].apply(removing_numbers)     # step 3: remove numbers\n",
        "        df['content'] = df['content'].apply(removing_punctuations)# step 4: remove punctuations\n",
        "        df['content'] = df['content'].apply(removing_urls)        # step 5: remove URLs\n",
        "        df['content'] = df['content'].apply(lemmatization)        # step 6: lemmatization\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f'Error during text normalization: {e}')            # print error if any\n",
        "        raise\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5tmSteZ53iTU",
        "outputId": "3d91db07-616d-4295-f031-cf66eae2c92a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>empty</td>\n",
              "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>layin n bed headache ughhhh waitin call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>want hang friend soon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>dannycastillo want trade someone houston ticke...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                            content\n",
              "0       empty  tiffanylue know listenin bad habit earlier sta...\n",
              "1     sadness            layin n bed headache ughhhh waitin call\n",
              "2     sadness                     funeral ceremony gloomy friday\n",
              "3  enthusiasm                              want hang friend soon\n",
              "4     neutral  dannycastillo want trade someone houston ticke..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = normalize_text(df)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "w22hDo0e3iTV",
        "outputId": "8e7602af-4fe2-4f97-cf5c-4c32f6801183"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i18ZJ6zj3iTV"
      },
      "outputs": [],
      "source": [
        "# create a boolean mask where sentiment is either 'happiness' or 'sadness'\n",
        "x = df['sentiment'].isin(['happiness', 'sadness'])\n",
        "\n",
        "# filter the DataFrame using the mask (keep only happiness and sadness rows)\n",
        "df = df[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "rvlt3PQI3iTW",
        "outputId": "00f748fa-7546-418b-cd7d-eed4c369942c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\aamir\\AppData\\Local\\Temp\\ipykernel_2956\\4269443875.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['sentiment'] = df['sentiment'].replace({'sadness': 0, 'happiness': 1})\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>layin n bed headache ughhhh waitin call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>sleep im not thinking old friend want married ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>charviray charlene love miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>kelcouch sorry least friday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            content\n",
              "1          0            layin n bed headache ughhhh waitin call\n",
              "2          0                     funeral ceremony gloomy friday\n",
              "6          0  sleep im not thinking old friend want married ...\n",
              "8          0                       charviray charlene love miss\n",
              "9          0                        kelcouch sorry least friday"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# replace sentiment labels with numeric values (sadness → 0, happiness → 1)\n",
        "df['sentiment'] = df['sentiment'].replace({'sadness': 0, 'happiness': 1})\n",
        "\n",
        "# display the first 5 rows of the DataFrame\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "kffHLkHcMxAc",
        "outputId": "f42f5a15-9145-4094-e7c6-a22cdfb8095e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21417</th>\n",
              "      <td>1</td>\n",
              "      <td>anyone need help image let know convo forum s ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27129</th>\n",
              "      <td>0</td>\n",
              "      <td>smell like beach job</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24945</th>\n",
              "      <td>0</td>\n",
              "      <td>sore yesterday definitely feeling hill now leg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21302</th>\n",
              "      <td>1</td>\n",
              "      <td>forgot lumpia pancit fridge last night yay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15241</th>\n",
              "      <td>0</td>\n",
              "      <td>missing best friend commme back kayla going li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4301</th>\n",
              "      <td>1</td>\n",
              "      <td>back home great time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26567</th>\n",
              "      <td>1</td>\n",
              "      <td>diannemr like that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24582</th>\n",
              "      <td>1</td>\n",
              "      <td>macmuso thank much glad like them</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4912</th>\n",
              "      <td>0</td>\n",
              "      <td>well only one week left holiday sad sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10628</th>\n",
              "      <td>0</td>\n",
              "      <td>ayy fml nothing perfect</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentiment                                            content\n",
              "21417          1  anyone need help image let know convo forum s ...\n",
              "27129          0                               smell like beach job\n",
              "24945          0  sore yesterday definitely feeling hill now leg...\n",
              "21302          1         forgot lumpia pancit fridge last night yay\n",
              "15241          0  missing best friend commme back kayla going li...\n",
              "4301           1                               back home great time\n",
              "26567          1                                 diannemr like that\n",
              "24582          1                  macmuso thank much glad like them\n",
              "4912           0            well only one week left holiday sad sad\n",
              "10628          0                            ayy fml nothing perfect"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "QcqPbV_N3iTW"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df['content'])\n",
        "y = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Au0re9WF3iTX"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "6f695023a93641e8917eed5b023ee458",
            "3ac185a7b1cf4934bbc79c3144312cda"
          ]
        },
        "id": "aK34vaiy3iTX",
        "outputId": "ebde1faa-27a4-4a3f-ac18-afaf7fe1072c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as aamir490\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as aamir490\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"aamir490/mlops-mini-project\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"aamir490/mlops-mini-project\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository aamir490/mlops-mini-project initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository aamir490/mlops-mini-project initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/10 08:05:35 INFO mlflow.tracking.fluent: Experiment with name 'Logistic Regression Baseline' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='mlflow-artifacts:/b5379880dab44d6c976de7b741d42aef', creation_time=1757471735135, experiment_id='1', last_update_time=1757471735135, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dagshub\n",
        "\n",
        "# https://dagshub.com/aamir490/mlops-mini-project.mlflow\n",
        "mlflow.set_tracking_uri('https://dagshub.com/aamir490/mlops-mini-project.mlflow')\n",
        "dagshub.init(repo_owner='aamir490', repo_name='mlops-mini-project', mlflow=True)\n",
        "\n",
        "mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
        "#mlflow.set_experiment(\"Logistic Regression Baseline v2\")\n",
        "\n",
        "# https://dagshub.com/aamir490/mlops-mini-project.mlflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9_1bFeAvdgg"
      },
      "source": [
        "# Now our experiment start :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "# Remove the old folder if it exists\n",
        "if os.path.exists(\"saved_model\"):\n",
        "    shutil.rmtree(\"saved_model\")\n",
        "\n",
        "# Now save safely\n",
        "mlflow.sklearn.save_model(model, \"saved_model\")\n",
        "mlflow.log_artifact(\"saved_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7769\n",
            "Precision: 0.7690\n",
            "Recall: 0.7773\n",
            "F1 Score: 0.7732\n",
            "✅ Model + metrics logged successfully 🚀\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# import mlflow\n",
        "# import joblib\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# # Start an MLflow run\n",
        "# with mlflow.start_run():\n",
        "\n",
        "#     # -----------------------------\n",
        "#     # Log preprocessing parameters\n",
        "#     # -----------------------------\n",
        "#     mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
        "#     mlflow.log_param(\"num_features\", 1000)\n",
        "#     mlflow.log_param(\"test_size\", 0.2)\n",
        "\n",
        "#     # -----------------------------\n",
        "#     # Model building and training\n",
        "#     # -----------------------------\n",
        "#     model = LogisticRegression()\n",
        "#     model.fit(X_train, y_train)\n",
        "\n",
        "#     # Log model type\n",
        "#     mlflow.log_param(\"model\", \"Logistic Regression\")\n",
        "\n",
        "#     # -----------------------------\n",
        "#     # Model evaluation\n",
        "#     # -----------------------------\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     accuracy = accuracy_score(y_test, y_pred)\n",
        "#     precision = precision_score(y_test, y_pred)\n",
        "#     recall = recall_score(y_test, y_pred)\n",
        "#     f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "#     # Log metrics\n",
        "#     mlflow.log_metric(\"accuracy\", accuracy)\n",
        "#     mlflow.log_metric(\"precision\", precision)\n",
        "#     mlflow.log_metric(\"recall\", recall)\n",
        "#     mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "#     # -----------------------------\n",
        "#     # Log the trained model as artifact\n",
        "#     # -----------------------------\n",
        "#     model_path = \"logreg_model.pkl\"\n",
        "#     joblib.dump(model, model_path)\n",
        "#     mlflow.log_artifact(model_path, artifact_path=\"models\")  # DagsHub-compatible\n",
        "\n",
        "#     # -----------------------------\n",
        "#     # Save and log the notebook\n",
        "#     # -----------------------------\n",
        "#     notebook_path = r\"E:\\Campus-X\\campusx_mlops\\campusx_projectt\\mlops-mini-project\\notebooks\\exp1_baseline_model (1).ipynb\"\n",
        "#     os.system(f\"jupyter nbconvert --to notebook --execute --inplace \\\"{notebook_path}\\\"\")\n",
        "#     mlflow.log_artifact(notebook_path)\n",
        "\n",
        "#     # -----------------------------\n",
        "#     # Print results\n",
        "#     # -----------------------------\n",
        "#     print(f\"Accuracy: {accuracy}\")\n",
        "#     print(f\"Precision: {precision}\")\n",
        "#     print(f\"Recall: {recall}\")\n",
        "#     print(f\"F1 Score: {f1}\")\n",
        "#     print(\"✅ Model + metrics logged successfully 🚀\")\n",
        "\n",
        "    \n",
        "\n",
        "# # code 2    \n",
        "import os\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ✅ Safety: end any previous active run\n",
        "mlflow.end_run()\n",
        "\n",
        "with mlflow.start_run():\n",
        "    # Log preprocessing params\n",
        "    mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
        "    mlflow.log_param(\"num_features\", 1000)\n",
        "    mlflow.log_param(\"test_size\", 0.2)\n",
        "\n",
        "    # Train model\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Log model params\n",
        "    mlflow.log_param(\"model\", \"Logistic Regression\")\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    # ✅ Save + log model as artifact\n",
        "    model_dir = \"saved_model\"\n",
        "    if os.path.exists(model_dir):\n",
        "        import shutil\n",
        "        shutil.rmtree(model_dir)  # clear old folder if exists\n",
        "\n",
        "    mlflow.sklearn.save_model(model, model_dir)\n",
        "    mlflow.log_artifact(model_dir)\n",
        "\n",
        "    # Log the notebook\n",
        "    notebook_path = r\"E:\\Campus-X\\campusx_mlops\\campusx_projectt\\mlops-mini-project\\notebooks\\exp1_baseline_model (1).ipynb\"\n",
        "    os.system(f\"jupyter nbconvert --to notebook --execute --inplace \\\"{notebook_path}\\\"\")\n",
        "    mlflow.log_artifact(notebook_path)\n",
        "\n",
        "    # Print results for quick check\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"✅ Model + metrics logged successfully 🚀\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64oq4WKz3iTY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".myvenv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ac185a7b1cf4934bbc79c3144312cda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f695023a93641e8917eed5b023ee458": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3ac185a7b1cf4934bbc79c3144312cda",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠹</span> Waiting for authorization\n</pre>\n",
                  "text/plain": "\u001b[32m⠹\u001b[0m Waiting for authorization\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
